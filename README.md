# ğŸŒ± Location-Based Plant Care Chatbot


ğŸ¯ Key Objectives Achieved
	â€¢	âœ… Strong Retrieval-Augmented Generation (RAG) enforcement
	â€¢	âœ… OpenAI used only as a reasoning & language layer
	â€¢	âœ… Location-aware contextualization (weather, air, environment)
	â€¢	âœ… Conversational memory support
	â€¢	âœ… Frontendâ€“Backend decoupled architecture
	â€¢	âœ… Vision pipeline provisioned (image optional, non-mandatory)
	â€¢	âœ… No hallucinations, no fallback to generic LLM knowledge

â¸»

ğŸ§  Architectural Philosophy

LLMs are not a source of truth. They are a reasoning layer.

The system strictly follows this pipeline:

User Input (Text / Image / Location)
        â†“
Environment APIs (Weather, AQI, Climate)
        â†“
Vector Retrieval (Internal Knowledge Base)
        â†“
LLM (Reasoning + Language Only)
        â†“
Grounded, Context-Specific Plant Care Response

ğŸš« Hard Rule Enforced

No RAG â†’ No Answer

If the retriever does not return relevant knowledge chunks, the system explicitly refuses to answer.

â¸»

ğŸ”’ Hallucination Prevention Strategy

The LLM is constrained using:
	â€¢	Explicit system prompts:
	â€¢	â€œAnswer using ONLY the provided plant knowledgeâ€
	â€¢	â€œIf insufficient information exists, say soâ€
	â€¢	Context isolation:
	â€¢	Retrieved chunks = authoritative
	â€¢	Conversation memory = supportive only
	â€¢	Environment data = modifier, not knowledge
	â€¢	Deterministic temperature settings

This ensures zero hallucination tolerance.

â¸»

ğŸ§© Core Capabilities in Phase-1

ğŸŒ Location Awareness
	â€¢	City â†” Latitude/Longitude â†” Map pin fully synchronized
	â€¢	Environment parameters fetched dynamically:
	â€¢	Temperature
	â€¢	Humidity
	â€¢	Rainfall
	â€¢	Air quality indicators
	â€¢	Environmental context explicitly reflected in answers

â¸»

ğŸ§  Strong RAG System
	â€¢	Internal curated plant knowledge base
	â€¢	Vector database for semantic retrieval
	â€¢	Query-time grounding enforced
	â€¢	No external plant knowledge leakage

â¸»

ğŸ–¼ï¸ Vision-Ready (Optional Input)
	â€¢	Image upload supported (non-mandatory)
	â€¢	Text-only, image-only, and text+image flows handled
	â€¢	Vision embeddings pipeline provisioned for Phase-2

â¸»

ğŸ’¬ Conversational Memory
	â€¢	Session-aware dialogue
	â€¢	Past context influences phrasing, not facts
	â€¢	Memory never overrides retrieved knowledge

â¸»

ğŸ–¥ï¸ Frontend UX (Phase-1)
	â€¢	Clean, map-based location selection
	â€¢	Bi-directional sync:
	â€¢	City â†’ Map â†’ Coordinates
	â€¢	Map â†’ City â†’ Coordinates
	â€¢	Environment cards displayed per location
	â€¢	Non-blocking UI (optional text/image inputs)

â¸»

ğŸ§ª Technology Stack

Layer	Tech
Frontend	HTML, CSS, JavaScript, Leaflet.js
Backend	FastAPI
Vector DB	ChromaDB
Embeddings	OpenAI embeddings
LLM	OpenAI (reasoning only)
Environment Data	Public weather & air APIs
Deployment-Ready	Local â†’ AWS / Azure


â¸»

ğŸ” Security & Responsibility
	â€¢	No user PII stored
	â€¢	No raw datasets sent to LLM
	â€¢	Only retrieved snippets passed to OpenAI
	â€¢	Designed for safe expansion into production environments

